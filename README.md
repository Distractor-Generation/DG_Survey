# DG_Survey
This is reading list for **Distractor Generation for Multiple-Choice Questions: A Survey of Methods, Datasets, and Evaluation**

It contains (Recommended Reading Papers, Dataset Links)

## Recommended Reading Papers
### Surveys
* A Survey of Natural Language Generation (ACM Computing Surveys) [Paper](https://dl-acm-org.simsrad.net.ocs.mq.edu.au/doi/10.1145/3554727)
* A Review on Question Generation from Natural Language Text (ACM Transactions on Information Systems) [Paper](https://dl.acm.org/doi/abs/10.1145/3468889)
* A Systematic Review of Automatic Question Generation for Educational Purposes ( International Journal of Artificial Intelligence in Education ) [Paper](https://link.springer.com/article/10.1007/s40593-019-00186-y)
* Automatic Multiple Choice Question Generation From Text: A Survey (IEEE Transactions on Learning Technologies) [Paper](https://ieeexplore.ieee.org/abstract/document/8585151)
* Automatic question generation and answer assessment: a survey (Research and Practice in Technology Enhanced Learning) [Paper](https://telrp.springeropen.com/articles/10.1186/s41039-021-00151-1)
* Survey of Hallucination in Natural Language Generation  (ACM Computing Surveys) [Paper](https://dl.acm.org/doi/abs/10.1145/3571730)
* A Survey of Controllable Text Generation Using Transformer-based Pre-trained Language Models (ACM Computing Surveys) [Paper](https://dl.acm.org/doi/abs/10.1145/3617680)

### Multiple-Choice Distractor Generation
* A novel approach to generate distractors for multiple choice questions (Expert Systems with Applications) [Paper](https://www.sciencedirect.com/science/article/pii/S0957417423005249)
* Revup: Automatic Gap-fill Question Generation from Educational Texts (BEA) [Paper](https://aclanthology.org/W15-0618.pdf)
* Questimator: Generating Knowledge Assessments for Arbitrary Topics (IJCAI) [Paper](https://www.ijcai.org/Proceedings/16/Papers/524.pdf)
* Multisource Soft Labeling and Hard Negative Sampling for Retrieval Distractor Ranking (IEEE Transactions on Learning Technologies) [Paper](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4620076)
* Learning to Reuse Distractors to Support Multiple-Choice Question Generation in Education (IEEE Transactions on Learning Technologies) [Paper](https://ieeexplore.ieee.org/abstract/document/9969921)
* Distractor Generation based on Text2Text Language Models with Pseudo Kullback-Leibler Divergence Regulation (ACL) [Paper](https://aclanthology.org/2023.findings-acl.790/)
* Knowledge-Driven Distractor Generation for Cloze-Style Multiple Choice Questions  (AAAI) [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/16559)
* CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model (EMNLP) [Paper](https://aclanthology.org/2022.findings-emnlp.429/)
* Difficulty-aware Distractor Generation for Gap-Fill Items (ALTA) [Paper](https://aclanthology.org/U19-1021.pdf)
* Automatic Generation of Distractors for Fill-in-the-Blank Exercises with Round-Trip Neural Machine Translation (ACL) [Paper](https://aclanthology.org/2022.acl-srw.31/)
* A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education (ACE) [Paper](https://dl.acm.org/doi/abs/10.1145/3636243.3636256)

### Reading Comprehension Distractor Generation
* Sequence to sequence learning with neural networks (NeurIPS) [Paper](https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html)
* Effective Approaches to Attention-based Neural Machine Translation (EMNLP)(https://aclanthology.org/D15-1166.pdf)
* Generating distractors for reading comprehension questions from real examinations  (AAAI) [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/4606)
* Co-attention hierarchical network: Generating coherent long distractors for reading comprehension  (AAAI) [Paper](https://ojs.aaai.org/index.php/AAAI/article/view/6522)
* Automatic Distractor Generation for Multiple Choice Questions in Standard Tests  (COLING) [Paper](https://aclanthology.org/2020.coling-main.189/)
* QDG: A unified model for automatic question-distractor pairs generation  (Applied Intelligence) [Paper](https://link.springer.com/article/10.1007/s10489-022-03894-6)
* Learning to distract: A hierarchical multi-decoder network for automated generation of long distractors for multiple-choice questions for reading comprehension (CIKM) [Paper](https://dl.acm.org/doi/abs/10.1145/3340531.3411997)
* A BERT-based Distractor Generation Scheme with Multi-tasking and Negative Answer Training Strategies  (EMNLP) [Paper](https://aclanthology.org/2020.findings-emnlp.393/)
* Diverse distractor generation for constructing high-quality multiple choice questions  (ACM Transactions on Audio, Speech, and Language) [Paper](https://ieeexplore.ieee.org/abstract/document/9664245)

### Multi-Modal Distractor Generation
* Good, better, best: Textual distractors generation for multiple-choice visual question answering via reinforcement learning (CVPR) [Paper](https://openaccess.thecvf.com/content/CVPR2022W/ODRUM/html/Lu_Good_Better_Best_Textual_Distractors_Generation_for_Multiple-Choice_Visual_Question_CVPRW_2022_paper.html)

## Dataset - [Paper] (Publisher) [Dataset Link]
* CLOTH  - [Large-scale Cloze Test Dataset Created by Teachers] (EMNLP) [Dataset](https://www.cs.cmu.edu/~glai1/data/cloth/)
* SCDE   - [SCDE: Sentence Cloze Dataset with High Quality Distractors From Examinations] (ACL) [Dataset](https://vgtomahawk.github.io/sced.html)
* DGen   - [Knowledge-Driven Distractor Generation for Cloze-Style Multiple Choice Questions] (AAAI) [Dataset](https://github.com/DRSY/DGen)
* CELA - [Cloze Quality Estimation for Language Assessment] (EACL) [Dataset](https://github.com/zz-zhang/cloze-quality-estimation)
* SciQ - [Crowdsourcing Multiple Choice Science Questions] (WNUT) [Dataset](https://allenai.org/data/sciq)
* AQUA-RAT  - [Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems] (ACL) [Dataset](https://github.com/google-deepmind/AQuA)
* OpenBookQA  - [Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering] (EMNLP) [Dataset](https://allenai.org/data/open-book-qa)
* ARC - [Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge] (AI2) [Dataset](https://allenai.org/data/arc)
* CommonsenseQA - [CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge] (NAACL) [Dataset](https://www.tau-nlp.sites.tau.ac.il/commonsenseqa)
* MCQL - [Distractor Generation for Multiple Choice Questions Using Learning to Rank] (BEA) [Dataset](https://github.com/harrylclc/LTR-DG)
* MathQA  - [MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms] (NAACL) [Dataset](https://math-qa.github.io/)
* QASC  - [QASC: A Dataset for Question Answering via Sentence Composition] (AAAI) [Dataset](https://allenai.org/data/qasc)
* MedMCQA  - [MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering] (PMLR) [Dataset](https://github.com/MedMCQA/MedMCQA?tab=readme-ov-file)
* Televic - [Learning to Reuse Distractors to Support Multiple-Choice Question Generation in Education] (IEEE Transactions on Learning Technologies) [Dataset](https://ieee-dataport.org/documents/distractor-retrieval-dataset), [Sample Test](https://github.com/semerekiros/dist-retrieval)
* EduQG   - [EduQG: A Multi-Format Multiple-Choice Dataset for the Educational Domain] (IEEE Access) [Dataset](https://github.com/hadifar/question-generation)
* ChildrenBookTest  - [The Goldilocks principle: Reading childrenâ€™s books with explicit memory representations] (ICLR) [Dataset](https://github.com/facebookresearch/ParlAI/tree/main/parlai/tasks/cbt)
* WhoDidWhat  - [Whodid What: ALarge-Scale Person-Centered Cloze Dataset] (EMNLP) [Dataset](https://tticnlp.github.io/who_did_what/)
* MCTest - [MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text ] (EMNLP) [Dataset](https://github.com/mcobzarenco/mctest/tree/master)
* RACE - [RACE: Large-scale ReAding Comprehension Dataset From Examinations] (EMNLP) [Dataset](https://www.cs.cmu.edu/~glai1/data/race/)
* RACE-C - [A New Multi-choice Reading Comprehension Dataset for Curriculum Learning] (PMLR) [Dataset](https://github.com/mrcdata/race-c)
* DREAM - [DREAM: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension] (TACL) [Dataset](https://dataset.org/dream/)
* CosmosQA - [Cosmos QA: Machine Reading Comprehension with Contextual Commonsense Reasoning] (EMNLP) [Dataset](https://wilburone.github.io/cosmos/)
* ReClor - [ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning] (ICLR) [Dataset](https://whyu.me/reclor/)
* QuAIL - [Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks] (AAAI) [Dataset](https://github.com/text-machine-lab/quail)
* MovieQA - [MovieQA: Understanding Stories in Movies Through Question-Answering] (CVPR) [Dataset](https://metatext.io/datasets/movieqa)
* Visual7W - [Visual7W: Grounded Question Answering in Images] (CVPR) [Dataset](https://ai.stanford.edu/~yukez/visual7w/)
* TQA - [Are You Smarter Than a Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension] (CVPR) [Dataset](https://allenai.org/data/tqa)
* RecipeQA - [RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes] (EMNLP) [Dataset](https://hucvl.github.io/recipeqa/)
* ScienceQA - [Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering] (NeurIPS) [Dataset](https://scienceqa.github.io/#dataset)


  
